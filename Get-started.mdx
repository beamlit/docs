---

title: 'Get started'

description: 'Deploy your first AI agent worldwide in just 3 minutes.'

---

<Frame>
<img src="/img/general/functions-dark.png" />
</Frame>

[Blaxel](https://app.blaxel.ai/) is a computing platform that enables developers to **push and run AI agents in a production-critical environment** in a single click. This tutorial demonstrates how to deploy your first AI agent on Blaxel.

## Quickstart

Welcome there! ðŸ‘‹ Make sure you have created an account on Blaxel (here â†’ [https://app.blaxel.ai](https://app.blaxel.ai)), and created a first [workspace](Security/Workspace-access-control). 

<Tip>Upon creating a workspace, Blaxel automatically adds a sandbox connection to a model API to get you started. [Model APIs](Models/Overview) provide developers with a centralized interface that simplifies credential management and LLM provider access.</Tip>

<Steps>

<Step title="Install Blaxel CLI">

<AccordionGroup>

<Accordion title="Install on Mac" icon="apple">

<Warning>To install Blaxel CLI, you must use [Homebrew](https://brew.sh/): make sure it is installed on your machine. We are currently in the process of supporting additional installers. Please reach out to [support@blaxel.ai](mailto:support@blaxel.ai) if you need to use an alternative to Homebrew.</Warning>

Install Blaxel CLI by running the two following commands successively in a terminal:

```shell 

brew tap beamlit/blaxel

```

```shell 
brew install blaxel

```

</Accordion>

<Accordion title="Install on Linux" icon="linux">

Install Blaxel CLI by running the following command in a terminal (alternatives below):

```shell 
curl -fsSL \
https://raw.githubusercontent.com/beamlit/toolkit/main/install.sh \
| BINDIR=/usr/local/bin sudo -E sh
```

If you need to specify a version (e.g. 0.36.0):

```shell 
curl -fsSL \
https://raw.githubusercontent.com/beamlit/toolkit/main/install.sh \
| VERSION=0.36.0 BINDIR=$HOME/.local/bin sh
```

</Accordion>

<Accordion title="Install with cURL" icon="code">

Install Blaxel CLI by running the following command in a terminal (alternatives below):

```shell 
curl -fsSL \
https://raw.githubusercontent.com/beamlit/toolkit/main/install.sh \
| BINDIR=/usr/local/bin sudo -E sh
```

If you need to specify a version (e.g. 0.36.0):

```shell 
curl -fsSL \
https://raw.githubusercontent.com/beamlit/toolkit/main/install.sh \
| VERSION=0.36.0 BINDIR=$HOME/.local/bin sh
```

</Accordion>

<Accordion title="Install on Windows" icon="windows">

For the most reliable solution, we recommend adapting the aforementioned Linux commands by using Windows Subsystem for Linux.

 

First install WSL (Windows Subsystem for Linux) if not already installed. This can be done by:

- Opening PowerShell as Administrator
- Running: `wsl --install -d Ubuntu-20.04`
- Restarting the computer
- From the Microsoft Store, install the Ubuntu app
- Run the command line using the aforementioned Linux installation process. Make sure to install using **sudo**.

</Accordion>

</AccordionGroup>

</Step>

<Step title="Login">

<Accordion title="Login to Blaxel via the CLI.">
Run the following command in a terminal to login to Blaxel. 

```bash
bl login your-workspace-slug
```

</Accordion>

</Step>

<Step title="Install a package manager (if not done already)">

<AccordionGroup>

<Accordion title="Python: install uv">
Follow the [uv documentation](https://docs.astral.sh/uv/getting-started/installation/) for guidance on how to install **uv,** if not already installed.

</Accordion>

<Accordion title="TypeScript: install npm">
Follow the [npm documentation](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) for guidance on how to install **npm,** if not already installed.

</Accordion>

</AccordionGroup>

</Step>

<Step title="Create your first AI agent">

<Warning>In Python, you will need to [have *uv* installed](https://docs.astral.sh/uv/getting-started/installation/); in TypeScript, you will need to [have npm installed](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) for this.</Warning>

Letâ€™s initialize a first app. The following command creates a **pre-scaffolded local repository** ready for developing and deploying your agent on Blaxel.

```bash
bl create-agent-app my-agent
```

You can now [use the Blaxel SDK to develop](Agents/Develop-an-agent) your agent's core logic in `/my-agent/src/agent.py` (or `/my-agent/src/agent.ts`).

</Step>

<Step title="Test and deploy your AI agent">

Run the following command to serve your agent locally:

```bash
cd my-agent;
bl serve;
```

<Tip>Add the hot reload option in command bl serve --hotreload to have live reload so you can patch changes onto the agent server while it runs.</Tip>

Query your agent locally by making a **POST** request to this endpoint: [`http://localhost:1338`](http://localhost:1338) with the following payload format: `{"inputs": "Hello world!"}`:

```bash
curl -X POST -H "Content-Type: application/json" -d '{"inputs": "Hello world!"}' [http://localhost:1338](http://localhost:1338/)
```

To push to Blaxel, run the following command. Blaxel will handle the build and deployment:

```bash
bl deploy
```

Your agent is available behind a **global endpoint**  ðŸŒŽÂ . Read [this guide](Agents/Query-agents) on how to use it for HTTP requests.

</Step>

<Step title="Make a first inference">

Run a first inference on your Blaxel agent with the following command:

```bash
bl chat my-agent
```

This gives you a chat-like interface where you can interact with your agent! To use this when serving locally, just add option `--local` .

Alternatively, you can send requests to your production agent by running:

```bash
 bl run agent my-agent --data '{"inputs":"Hello world!"}'
```

Or by directly calling the [global endpoint](Agents/Query-agents).

</Step>

</Steps>

## Next steps

You are ready to run AI with Blaxel! Hereâ€™s a curated list of guides which may be helpful for you to make the most of the Blaxel platform, but feel free to explore the product on your own! 

<Card title="Deploy agents" icon="earth-americas" href="/Agents/Overview">
Complete guide for deploying AI agents on Blaxel.
</Card>

<Card title="Integrate and query agents" icon="bolt" href="/Agents/Query-agents">
Complete guide for querying your AI agents on the Global Inference Network.
</Card>

<Card title="Manage policies" icon="server" href="/Model-Governance/Policies">
Complete guide for managing deployment and routing policies on the Global Inference Network.
</Card>

## Any question?

Although we designed this documentation to be as comprehensive as possible, you are welcome to contact [support@blaxel.ai](mailto:support@blaxel.ai) or the community on [Discord](https://discord.gg/9fu69KEg) with any questions or feedback you have.

Want to deploy Blaxel on-prem?Â [**Schedule a call**](mailto:support@blaxel.ai)Â with us.