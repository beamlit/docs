---

title: 'Functions (MCP servers)'

sidebarTitle: "Overview"

description: 'Execute custom code to empower your AI agents with tools and actions.'

---

Functions (also called *MCP servers* on Blaxel) represent **custom code** that can be executed by passing specific input arguments. 

Blaxel runs your code on Global Inference Network, a high-availability and low-latency compute infrastructure. You only provide the code, and Blaxel automates its execution and scaling - providing you with one single globally endpoint to run the function. 

Functions are designed to **equip agents with tools** to interact with the world. When an agent runs on Blaxel, our Global Inference Network accelerates the whole execution behind the scenes, by running the function separately from the action model and agent logic. This ensures minimal latency for your consumers as well as optimal resource utilization. 

## Deploy a function on Blaxel

A function can be uploaded into Blaxel from a variety of origins.

- Using a function from the Blaxel Store
- From a custom code
- *From GitHub (coming soon!)*

### Deploy from the Blaxel store

The Blaxel store contains a curated list of functions and tools from the most popular providers that can be **deployed out-of-the-box on Blaxel**. They are lightweight programs that expose specific capabilities (accessing databases, APIs, local files, etc.) through the standardized [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP).

Depending on the function you choose, you will need to enter credentials as an [integration](../Integrations), such as an API key if your tool is using a third-party service provider.

<Card title="Invoke functions" icon="bolt" href="/Functions/Invoke-functions">
Learn how to run invocation requests on your function. 
</Card>