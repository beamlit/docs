---

title: 'Develop agents'

sidebarTitle: "Overview"

description: 'Run any custom AI agent on Beamlit.'

---

You can **bring agents developed in any framework** (LangChain, CrewAI, or any custom framework in Python) and deploy them on Beamlit by integrating a few lines of the Beamlit SDK and leveraging our other developer tools ([Beamlit CLI](../cli-reference), GitHub action, etc.).

To run your agent on Beamlit, you must package it by **using the Beamlit SDK** so Beamlit can identify the [core resources to deploy](Overview): the main agent code, the standalone tools/functions it can use, and the model APIs it can query. This is what allows Beamlit to enable its features when your agent is deployed, such as secure connections to third-party systems or private networks, smart global placement of workflows, and much more.

<Tip>Check out [this Getting Started](../Get-started) tutorial in order to develop and deploy your first Hello World AI agent globally in less than 5 minutes.</Tip>

## Overview of the development/deployment process

Beamlit’s development paradigm is designed to have a minimal footprint on your usual development process. Your custom code remains platform-agnostic: you can deploy it on Beamlit or through traditional methods like Docker containers on VMs or Kubernetes clusters. When you deploy on Beamlit (CLI command `bl deploy`), Beamlit runs a specialized build process that integrates your code with its [Global Inference Network](../Models/Global-Inference-Network) features.

<Warning>At this time, Beamlit only supports custom agents developed in TypeScript or Python.</Warning>

Here is a high-level presentation of how agents can be built and deployed using Beamlit:

1. **Initialize a new project by creating a local git repository**. This will contain your agent's logic, custom functions, and API connections, as well as all required dependencies. For quick setup, use [Beamlit CLI](../cli-reference) command `bl create-agent-app`, which creates a pre-scaffolded local repository ready for developing and deploying your agent on Beamlit.
2. **Develop and test your agent iteratively in a local environment**. 
    1. Develop your agent logic using an agentic framework (like LangChain) or any custom TypeScript/Python code. Write your own functions. Use Beamlit SDK wrappers and decorators on your core agent and functions to specify the resources to run on Beamlit.
    2. Use Beamlit CLI command `bl serve` to serve your agent on your local machine and get an endpoint for inference requests. The execution workflow—including agent logic, functions, and model API calls—is broken down and sandboxed exactly as it would be when served on Beamlit.
3. **Deploy your agent in the *development* environment**. Use Beamlit CLI command `bl deploy --env development` to build and deploy your agent on Beamlit’s [development environment](../Model-Governance/Environments).
4. **Promote your agent to the *production* environment**. Use Beamlit CLI command `bl deploy --env production` to build and deploy your agent on Beamlit’s [production environment](../Model-Governance/Environments).

<Note>See an example of [how to use the Beamlit SDK to develop and deploy a custom LangChain agent](../Examples/Deploy-a-LangChain-agent) in 5 minutes.</Note>

## Develop an agent on Beamlit

Check out the following guide to learn how to develop and deploy an agent using your preferred programming language on Beamlit.

<CardGroup cols={2}>  

<Card title="TypeScript" icon="js">    
Develop your AI agents in TypeScript using the Beamlit SDK.
</Card>

<Card title="Python" icon="python">    
Develop your AI agents in Python using the Beamlit SDK.
</Card>

</CardGroup>

<Card title="Deploy an agent" icon="server" href="/Agents/Deploy-an-agent">
Learn how to deploy your custom AI agents on Beamlit as a serverless endpoint. 
</Card>