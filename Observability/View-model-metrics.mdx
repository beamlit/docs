---

title: 'View model metrics'

description: 'Observe your deployment metrics in real-time.'

---

## Overview

View model metrics provides real-time observability for your model deployments on the Beamlit platform. This feature allows you to monitor and analyze various performance indicators, helping you optimize your AI infrastructure and ensure smooth operation of your models.

## Available Metrics

Beamlit offers the following key metrics for your model deployments:

- Requests per second: This metric can be computed on several scopes:
    - Total requests per second for the deployment
    - Requests per second by execution location
    - Requests per second by response code
- Total requests: The cumulative number of requests processed by your model deployment

## Benefits of Model Metrics

Monitoring your model metrics provides several advantages:

- Performance Optimization: Identify bottlenecks and optimize your model's performance
- Resource Management: Ensure efficient utilization of your Global Inference Network
- Error Detection: Quickly spot and address any issues with your model deployments
- Capacity Planning: Make informed decisions about scaling your infrastructure based on usage patterns

## Related Topics

To further enhance your understanding of Beamlit's observability features, consider exploring these related topics:

- [View model logs](/Observability/View-model-logs): Learn how to access and analyze logs for your model deployments
- [Global Inference Network](/Models/Global-Inference-Network): Understand how Beamlit's distributed infrastructure impacts your model's performance
- [Environments](/Model-Governance/Environments): Learn about managing different deployment environments and how they affect your metrics